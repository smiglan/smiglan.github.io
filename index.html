<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Shubham Miglani</title>
  <meta name="description" content="Shubham Miglani — Senior Machine Learning Engineer building production LLM systems for healthcare.">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@400;500;600;700&family=Source+Serif+4:opsz,wght@8..60,500;8..60,600&display=swap" rel="stylesheet">
  <script src="https://use.fontawesome.com/releases/v5.15.4/js/all.js" crossorigin="anonymous"></script>
  <link rel="stylesheet" href="css/styles.css">
</head>
<body>
  <div class="page">
    <aside class="sidebar">
      <img class="avatar" src="assets/img/profile.jpg" alt="Portrait of Shubham Miglani">
      <h1>Shubham Miglani</h1>
      <p class="role">Senior Machine Learning Engineer · Acentra Health</p>
      <p class="meta">San Jose, CA · miglanishubham25@gmail.com</p>
      <div class="links">
        <a href="https://linkedin.com/in/shubham-miglani" target="_blank" rel="noreferrer">LinkedIn</a>
        <a href="https://github.com/smiglan" target="_blank" rel="noreferrer">GitHub</a>
        <a href="assets/docs/Shubham_Miglani.pdf" target="_blank" rel="noreferrer">Resume</a>
        <a href="mailto:miglanishubham25@gmail.com">Email</a>
      </div>
      <div class="pill-group">
        <span>LLMs</span>
        <span>RAG</span>
        <span>Evaluation</span>
        <span>Data</span>
        <span>Infra</span>
      </div>
    </aside>

    <main class="content">
      <header class="intro">
        <nav class="nav">
          <a href="#about">About</a>
          <a href="#education">Education</a>
          <a href="#work">Experience</a>
          <a href="#skills">Skills</a>
          <a href="#builds">Builds</a>
          <a href="#projects">College projects</a>
          <a href="#blog">Blog & saves</a>
          <a href="#books">Book recommendations</a>
          <a href="#certifications">Certifications</a>
        </nav>
      </header>

      <section id="about" class="section">
        <div class="section-title">About</div>
        <p class="lede">I build production-grade agentic AI and LLM/RAG systems for healthcare. I like the full stack: data design, retrieval, autonomous tool use, evaluation loops, and the infrastructure that keeps it reliable and cost-aware.</p>
        <p class="body">I lead agentic and RAG initiatives at Acentra Health. Previously I productionized conversational AI, OCR, and NLP platforms at Bridgera and worked on computer vision acceleration at MathWorks.</p>
        <div class="now">
          <div class="label">Now</div>
          <ul>
            <li>Running a Bedrock + OpenSearch RAG platform ingesting 100M+ clinical docs annually with agentic tools for routing, extraction, and summarization.</li>
            <li>Building evaluation loops (judge models, groundedness, red-teaming), prompt caching, and telemetry to keep latency and cost in check.</li>
            <li>Coaching teams on LLM observability, retrieval quality, and safe agent behaviors in production workflows.</li>
          </ul>
        </div>
        <div class="now">
          <div class="label">Background</div>
          <p class="body">Applied ML/LLM engineer with roots in data pipelines, OCR/NLP, and computer vision; comfortable spanning retrieval architectures, agent tooling, evaluation, and cloud IaC.</p>
        </div>
      </section>

      <section id="education" class="section">
        <div class="section-title">Education</div>
        <div class="list">
          <article class="card">
            <div class="card-title">NC State University — M.S. Electrical Engineering (Machine Learning)</div>
            <div class="card-meta">GPA 4.0 · Dec 2020</div>
          </article>
          <article class="card">
            <div class="card-title">Punjab Engineering College — B.E. Electrical Engineering</div>
            <div class="card-meta">GPA 8.85/10 · May 2016</div>
          </article>
        </div>
      </section>

      <section id="work" class="section">
        <div class="section-title">Work</div>

        <article class="card">
          <header class="card-head">
            <div>
              <div class="card-title">Senior Machine Learning Engineer (Lead) · Acentra Health</div>
              <div class="card-meta">Jan 2024 – Present · San Jose, CA</div>
            </div>
          </header>
          <ul>
            <li>Built RAG infrastructure (Bedrock Knowledge Bases, OpenSearch, S3 pipelines) processing 100M+ clinical documents annually with high-throughput, low-latency retrieval and advanced RAG techniques.</li>
            <li>Implemented prompt caching for cost/latency gains while preserving grounding and freshness.</li>
            <li>Designed case summarization and Q&A workflows so nurses review concise AI output instead of thousands of pages, reducing review time by ~30%.</li>
            <li>Created evaluation frameworks with judge LLMs, custom factuality/grounding metrics, and manual feedback loops; unified AI APIs via API Gateway and IaC with AWS CDK.</li>
            <li>Built intelligent document processing on AWS that accelerated 35M+ Medicare documents by ~50% (<a class="link-pill" href="https://aws.amazon.com/blogs/publicsector/acentra-health-processes-35m-medicare-documents-50-faster-with-idp-on-aws/" target="_blank" rel="noreferrer">AWS case study</a>).</li>
            <li>Led Azure OpenAI + FastAPI + React document automation (MedScribe) cutting letter drafting time by ~50% and saving 11,000+ nursing hours annually (<a class="link-pill" href="https://www.microsoft.com/en/customers/story/19280-acentra-health-azure" target="_blank" rel="noreferrer">Azure story</a>).</li>
            <li>Bridged AI systems with clinical users: collaborated with nurses/QA/product on workflows, validation guidelines, and responsible deployment standards.</li>
            <li>Championed AI enablement via AI-DLC and onboarding to GitHub Copilot/Codex; mentored 5 engineers on LLM integration, RAG architecture, observability, and evaluation.</li>
          </ul>
        </article>

        <article class="card">
          <header class="card-head">
            <div>
              <div class="card-title">Machine Learning Engineer · Bridgera</div>
              <div class="card-meta">Apr 2021 – Dec 2023 · Raleigh, NC</div>
            </div>
          </header>
          <ul>
            <li>Architected and productionized 8+ conversational AI systems (company-wide RAG for documentation search) with Azure OpenAI, LangChain, and FAISS to support internal teams.</li>
            <li>Built a high-throughput OCR+NLP pipeline on AWS for 35M image-based PDFs annually, improving processing time by 50% and cutting costs by 40% via searchable conversion and auto-bookmarking.</li>
            <li>Led on-prem ML migrations to Azure with CI/CD (Azure DevOps), covering provisioning, configuration, and ongoing cost optimizations.</li>
          </ul>
        </article>

        <article class="card">
          <header class="card-head">
            <div>
              <div class="card-title">Engineering Development Group Intern · MathWorks</div>
              <div class="card-meta">May 2020 – Aug 2020 · Natick, MA</div>
            </div>
          </header>
          <ul>
            <li>Developed workflows to switch between domain libraries (OpenCV, Arm Compute) during C++ code generation for MATLAB image processing functions, improving performance on constrained hardware.</li>
          </ul>
        </article>

        <article class="card">
          <header class="card-head">
            <div>
              <div class="card-title">Intern · Sabre Travel Technologies</div>
              <div class="card-meta">Jan 2015 – Jul 2015</div>
            </div>
          </header>
          <ul>
            <li>Built automation scripts for data validation and performance testing for 55 JasperSoft reports (Java, MySQL).</li>
            <li>Modified 80 QTP scripts with recovery scenarios and generic patterns, boosting productivity by 60% (QTP, VBScript, HP ALM, JIRA).</li>
            <li>Used dynamic SQL queries for automated testing of business rules for RM GUI (MySQL, QTP, VBScript).</li>
          </ul>
        </article>

        <article class="card">
          <header class="card-head">
            <div>
              <div class="card-title">Assistant Manager, Body Shop Maintenance · Fiat Chrysler Automobiles</div>
              <div class="card-meta">Jul 2016 – Aug 2018</div>
            </div>
          </header>
          <ul>
            <li>Commissioned a new body shop line for Jeep Compass; optimized robot positioning, PLC logic, vision camera teaching for sealant application, and welding parameters to increase throughput.</li>
          </ul>
        </article>
      </section>

      <section id="skills" class="section">
        <div class="section-title">Skills</div>
        <div class="card">
          <ul class="fa-ul mb-0">
            <li><b>Programming Languages</b>: Python, R, SQL, C, C++, Matlab, Simulink</li>
            <li><b>Frameworks &amp; Libraries</b>: Scikit-learn, Pandas, Pyspark, TensorFlow, Keras, NumPy, XGBoost, nltk, spacy, OpenCV, ACL</li>
            <li><b>Machine Learning</b>: Linear &amp; logistic regression, Decision Trees, Random Forest, SVM, KNN, Clustering, PCA, boosting and bagging</li>
            <li><b>Deep Learning</b>: CNN, FFNN, GAN, VAE, RBM, RNN, LSTM, Attention, Transformers, BERT</li>
            <li><b>NLP</b>: RNN, LSTM, Transformers, Machine translation, Text classification &amp; summarization, NER, Topic Modelling</li>
            <li><b>Computer Vision</b>: Image classification, Object detection and tracking, Semantic segmentation and instance segmentation</li>
            <li><b>Miscellaneous</b>: AWS–S3 &amp; Machine Learning-Boto3, Apache Spark, Google Data Studio, Tableau, Docker, Git</li>
          </ul>
        </div>
      </section>

      <section id="builds" class="section">
        <div class="section-title">Builds</div>
        <div class="grid">
          <article class="card">
            <div class="card-title">Clinical RAG Platform</div>
            <p class="body">Unified ingestion, indexing, and retrieval across fragmented clinical docs with Bedrock KB + OpenSearch, backed by S3 pipelines and prompt caching. Tuned for fast handoffs to nurses and auditors.</p>
          </article>
          <article class="card">
            <div class="card-title">Generative Document Automation</div>
            <p class="body">Azure OpenAI + FastAPI + React tool that drafts letters and narratives; cut drafting time by ~50% and saved 11,000+ nursing hours annually.</p>
          </article>
          <article class="card">
            <div class="card-title">Document Digitization Pipeline</div>
            <p class="body">OCR/NLP pipeline for 35M+ PDFs/year with automated bookmarking, searchability, and downstream data services; built observability and cost controls into each stage.</p>
          </article>
        </div>
      </section>

      <section id="projects" class="section legacy">
        <div class="section-title">College projects (full archive)</div>
        <div class="legacy-block">
          <h3 class="mb-0">COLLEGE PROJECTS</h3>
          <h4><a href="https://github.com/smiglan/OCR-NER-for-medicine-name-from-drug-labels" target="_blank">OCR+NER for medicine name from drug labels</a></h4>
          <p>In this project, the task of medicine name identification from Drug Label bottles using Optical Character Recognition for image to text conversion and Named entity recognition for identifying the entity of the text from OCR was investigated.<br>This can be seen from the image below.<br>Given an image of a drug bottle, medicine name has to be idenitified and bounding boxes drawn around it.<br>Note: The green bounding box represents the medicine name <em>"PANTOPRAZOLE"</em></p>
          <p><img align="center" src="assets/img/boundingbox.png"></p>
          <p>Other parameters can also be identified such as in the example shown below using spacy's med7 model. Such as given the input text :<em>'A patient was prescribed Magnesium hydroxide 400mg/5ml suspension PO of total 30ml  bid for the next 5 days.'</em>, the results would be:</p>
          <p><img align="center" src="assets/img/NER_med7.JPG"></p>
          <p>This involes two steps:</p>
          <ul>
            <li>Optical character recognition for image to text conversion</li>
            <li>Named entity recognition for identifying medicine name</li>
          </ul>
          <p><strong>Tesseract Optical Character Recognition</strong>:</p>
          <ul>
            <li>For dateset generation and model training, three methods were used. The first involved using AWS Rekognition, second one involved using font files for synthetic data generation, whereas the third one involved using hocr-tools for generating image line data for Tesseract-OCR training.</li>
            <li>Various factors such as base model for model training, Configuration parameters such as Page Segmentation Mode, Thread limit, Preprocessing factors such as Re scaling method and size, different threshold methods for Binarization (Simple and Adaptive threshold) were analyzed for improving performance.</li>
          </ul>
          <p><strong>Named Entity recognition</strong>:</p>
          <ul>
            <li>Dataset generation in B-I-O tagging format</li>
          </ul>
          <p><img align="center" width="400" src="assets/img/BIO.JPG"></p>
          <ul>
            <li>Various models such as Memory tagger, Random forest classifier, Conditional Random Fields, Sequence tagging using LSTM were trained and their performance analyzed.</li>
          </ul>
          <p>The final model had an accuracy of 76% with an average time of 1 second per image as compared to the baseline tesseract with 50% accuracy and an average time of 2.24 second per image.</p>
          <p>The <a href="https://github.com/smiglan/OCR-NER-for-medicine-name-from-drug-labels/blob/master/Report.pdf" target="_blank">report</a> contains detailed instructions for the steps explained above.</p>

          <br><a href="https://github.com/smiglan/CNN-for-Leaf-Wilting-Detection-in-Soybean-Crops" target="_blank">CNN-for-Leaf-Wilting-Detection-in-Soybean-Crops</a>
          <ul>
            <li>Transfer learning (vgg-19) with data augmentation techniques for multi-classification of soybean crop images</li>
            <li>Semi-supervised Learning using unlabeled images based on ladder network where both supervised and unsupervised (autoencoder) parts are trained simultaneously to minimize the loss</li>
          </ul>
          <br><h4><a href="https://github.com/smiglan/Face-Detection-and-Recognition" target="_blank">Face-Detection-and-Recognition</a></h4>
          <h5 id="face-image-classification-using-gaussian-model-mixture-of-gaussian-model-tdistribution-factor-analysis">Face image classification using Gaussian model, Mixture of Gaussian model, tdistribution, Factor Analysis</h5>
          <p><strong>Data Preparation</strong>  (Data_Conversion.py)
          Extract n = 1000 training images for face and non-face respectively, and m = 100 testing images for face and non-face respectively from one of the provided 17 face datasets which has face bounding boxes
          annotated, both at 20 × 20 resolution. Make sure training face images and testing face images are separate, that is no face testing images are from the same person in the training set of face
          images. And, non-face images should be cropped randomly from background in the provided images in the dataset you selected.</p>
          <p><strong>Tasks</strong></p>
          <p>With your own face dataset created, you can train your models and test the performance.<br>For each model, report results as follows.</p>
          <ul>
            <li>Visualize the estimated mean(s) and covariance matrix for face and non-face respectively;</li>
            <li>Evaluate the learned model on the testing images using 0.5 as threshold for the posterior.
            Compute false positive rate (#negatives being classified as faces / #total negatives), and
            false negative rate (#positives being classified as non-face / #total positives), and the
            misclassification rate ((#false-positives + #false-negative)/#total testing images)</li>
            <li>Plot the ROC curve where x-axis represents false positive rate and y-axis true positive
            rate (i.e, 1-false negative rate).</li>
          </ul>
          <h5 id="adaptive-boosting-adaboost-for-face-detection">Adaptive Boosting (AdaBoost) for Face Detection</h5>
          <ul>
            <li>Reuse the dataset from above</li>
            <li>Use Harr feature. Compute the value of each Harr feature for each sample. Each feature corresponds to a weak learner. Determine the threshold between face samples and non-face samples for all the weak learners.
            Calculate the classification error for each weak learner and draw the best ten features<br><img align="center" width="400" src="assets/img/Haar.png"></li>
            <li>Implement the Adaboost Algorithm and plot the ROC</li>
          </ul>
          <h5 id="convolutional-neural-networks-for-face-image-classification">Convolutional Neural Networks for face image classification</h5>
          <ul>
            <li>Preprocess the data and select data augmentation</li>
            <li>Select the architecture</li>
            <li>Double check that the loss is reasonable without regularization</li>
            <li>Check loss with high regularization</li>
            <li>Overfitting with small data set.</li>
            <li>Checking loss with very small learning rate</li>
            <li>Checking loss with very high learning rate</li>
            <li>Checking loss for an upper bound for learning rate</li>
            <li>Hyperparameter tuning – Course to fine</li>
            <li>Model training and plots for validation loss and accuracy.</li>
          </ul>
          <h5 id="face-verification-and-recognition">Face Verification and Recognition</h5>
          <p><strong>Face Verification</strong> - "is this the claimed person?". For example, at some airports, you can pass through customs by letting a system scan your passport and then verifying that you (the person carrying the passport) are the correct person. A mobile phone that unlocks using your face is also using face verification. This is a 1:1 matching problem.<br><strong>Face Recognition</strong> - "who is this person?". For example, the video lecture showed a face recognition video of Baidu employees entering the office without needing to otherwise identify themselves. This is a 1:K matching problem.</p>
          <p>FaceNet learns a neural network that encodes a face image into a vector of 128 numbers. By comparing two such vectors, you can then determine if two pictures are of the same person.</p>
          <p>In this project, the following things were implemented:</p>
          <ul>
            <li>Implement the triplet loss function</li>
            <li>Use a pretrained model to map face images into 128-dimensional encodings</li>
            <li>Use these encodings to perform face verification and face recognition</li>
          </ul>

          <br><h4><a href="https://github.com/smiglan/Reinforcement-Learning-Optimal-Control-of-Human-Robot-Interaction-system" target="_blank">Reinforcement Learning Optimal Control of Human-Robot Interaction system</a></h4>
          <p>The problem of finding the optimal parameters of the model is transformed into an LQR problem which minimizes the human effort and optimizes the closed-loop behavior.
          As the human model is difficult to estimate, Reinforcement learning is used in the paper to solve the LQR problem.
          The plan for the project consisted of two tasks.</p>
          <ul>
            <li>The first part was the application of integral reinforcement learning</li>
            <li>the second part was using a neural network to find the optimal solution for LQR.</li>
          </ul>

          <br><h4><a href="https://github.com/smiglan/Image-Processing" target="_blank">Image Processing</a></h4>
          <h5 id="image-blending">Image Blending</h5>
          <p>This project contains the following implementations:</p>
          <ul>
            <li>Implement Gaussian and Laplacian pyramid, gPyr, lPyr = ComputePyr(input_image, num_layers)<br><em>Input arguments</em> : input_image is an input image (grey, or RGB), num_layers is the number of layers of the pyramid to be computed.<br>Depending on the size of input_image, num_layers needs to be checked if valid.<br>If not, use the maximum value allowed in terms of the size of input_image.<br><em>Outputs</em>: gPyr, lPyr are the Gaussian pyramid and Laplacian pyramid respectively.</li>
            <li>Write a simple GUI to create a black/white binary mask image. The GUI can open an image (e.g. the foreground image that you will use in blending); On the image, you can select a region of interest using either a rectangle or an eclipse, [optional] even some free-form region. Based on the opened image and the selected regions, the GUI can generate a black/white mask image of the same size as the opened image, in which the selected region(s) are white and the remaining black.</li>
            <li>On top of the functions in (a) and (b), write a function to implement Laplacian pyramid blending</li>
          </ul>
          <p>Example:</p>
          <p><img align="center" width="600" src="assets/img/ImageBleding1.JPG">
          <img align="center" width="600" src="assets/img/ImageBleding2.JPG"></p>
          <h5 id="two-dimensional_convolution">Two-dimensional_Convolution</h5>
          <p>Write a function to implement g = conv2(f,w, pad), where f is an input image (grey, or RGB), w is a 2-D kernel (e.g., 3 × 3 box filter), and pad represents the 4 padding type :
          clip/zero-padding, wrap around, copy edge, and reflect across edge, as illustrated in the following example</p>
          <p><img align="center" width="600" src="assets/img/Padding.JPG"></p>
          <p>Example Output of Convolution funciton for Sobel_X  filter:</p>
          <p><img align="center" width="600" src="assets/img/Sobelx.png"></p>
          <h5 id="2d-fft">2D FFT</h5>
          <p>Using the built-in 1-D FFT to implement F = DFT2(f) from scratch, where f is an input grey image.<br>Using the DFT2 to implement the inverse FFT of an input transform F, g = IDFT2(F) from scratch.</p>
          <h5 id="smoothness-prior">Smoothness Prior</h5>
          <p>Given an image I, consider all valid pairs of neighboring pixels, compute the difference between their intensity or color values, and plot the histogram.</p>
          <ul>
            <li><strong>Neighbors</strong>: e.g., for a 100x100 image, consider all valid pairs of (x, y) and (x + 1, y).</li>
            <li><strong>Difference</strong>: using the squared of difference for intensity, RGB, HSV and Lab.</li>
            <li><strong>Histogram</strong>: Visualize the histogram.</li>
          </ul>

          <br><h4><a href="https://github.com/smiglan/Algorithms" target="_blank">Algorithms</a></h4>
          <h5 id="__sorting__"><strong>Sorting</strong></h5>
          <p>In this assignment, 3 sorting algorithms were implemented: bubble sort, quick sort, and
          merge sort and compared again files of different sizes starting from 2500 lines to 1 million lines</p>
          <p>The following plots are recorded for growth of sorting time as a function of data size:</p>
          <p>Note, that in bubble sort, for 1Ma, 1Mb, 1Mc, only 50000 lines are used due to
          excessive time requirements. Also, 1Ma, Mb and 1Mc files have 1 million lines with different configurations</p>
          <p><img align="center" width="600" src="assets/img/bubble_sort_time.JPG">
          <img align="center" width="600" src="assets/img/merge_sort_time.JPG">
          <img align="center" width="600" src="assets/img/quick_sort_time.JPG"></p>
          <h5 id="__regular-expressions__"><strong>Regular Expressions</strong></h5>
          <p>Design and implement solutions for the following problems.</p>
          <p><em>DIALOG</em>: Given a list of input files similar to the sample files (but not previously known), extract
          all the dialog into a separate output file. In the output, retain the quotation or other
          marks that separate the dialog from the narrative.</p>
          <p><em>DIALOG SEARCH</em>: Given one input file similar to the sample files (but not previously known),
          and a search string, determine if the search string appears within dialog in the sample
          file. If it does, then output each Chapter number/title (equivalently for anthologies,
          the number/name of the individual work) in which the search string appears.
          Example:</p>
          <p><em>DIALOG</em></p>
          <p>To run the script, navigate to the appropriate folder and run the script dialogscript.py</p>
          <p>The result of running this script is as follows:<br><code>File output successful with file name outputdracula.txt</code><br><code>File output successful with file name outputsh.tx</code></p>
          <p>These files contains all the dialog sepearated into a separate output file.</p>
          <p><em>DIALOG SEARCH</em></p>
          <p>To run the script, navigate to the appropriate folder and run the script dialogsearchscript.py</p>
          <p>The result of running this script is as follows:<br><code>filename : dracula.txt</code><br><code>search string : red eyes</code><br><code>Found in CHAPTER VII CUTTING FROM "THE DAILYGRAPH," 8 AUGUST</code><br><code>Found in CHAPTER VII CUTTING FROM "THE DAILYGRAPH," 8 AUGUST</code><br><code>Found in CHAPTER XI Lucy Westenra's Diary.</code><br><code>Found in CHAPTER XIX JONATHAN HARKER'S JOURNAL</code><br><code>Found in CHAPTER XXVII MINA HARKER'S JOURNAL</code></p>
          <h5 id="__diff-using-dynamic-programming-approach-to-longest-common-subsequence__"><strong>Diff using dynamic programming approach to Longest Common Subsequence</strong></h5>
          <p>This assignment had the following three parts:</p>
          <ul>
            <li>Implement a hash function for strings. Use a modulo function to compress the resulting value to 10 bits, i.e. to be in the range [0, 1023].</li>
            <li>Use your hash function to implement a hashfile program that takes a filename on
            the command line and produces a 10-bit hash of each line.</li>
            <li>Implement the dynamic programming algorithm for diff, using the dynamic programming
            approach to the Longest Common Subsequence problem. Use the code from your hashfile
            implementation.</li>
          </ul>
          <h5 id="__shortestpath-using-bfs__"><strong>Shortest-Path using Breadth-First-Search</strong></h5>
          <p>Finding the 4-, 8-, or m-shortest path in an image (graph)</p>
          <ul>
            <li>Input arguments: an image, a predefined set V, two pixel locations p and q
            inside the image, the path type (4-, 8-, or m-path)</li>
            <li>Outputs: the length of the shortest path, and the path (i.e., the sequence of
            pixels)</li>
          </ul>
        </div>
      </section>

      <section id="blog" class="section stack">
        <div class="section-title">Blog & saves</div>
        <article class="card">
          <div class="card-title">My posts</div>
          <ul>
            <li><a class="card-link" href="https://medium.com/@miglanishubham25/from-on-device-ocr-to-llms-lessons-from-a-2019-medical-nlp-project-530d696c73a9" target="_blank" rel="noreferrer">From on-device OCR to LLMs: lessons from a 2019 medical NLP project</a></li>
            <li><span class="pill">Coming soon</span> Agentic RAG evaluation loops in healthcare</li>
            <li><span class="pill">Coming soon</span> Prompt caching patterns that don’t break grounding</li>
          </ul>
        </article>
        <article class="card">
          <div class="card-title">Saved reads</div>
          <ul>
            <li><a class="card-link" href="https://arxiv.org/abs/2005.11401" target="_blank" rel="noreferrer">Retrieval-Augmented Generation for Knowledge-Intensive NLP</a></li>
            <li><a class="card-link" href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html" target="_blank" rel="noreferrer">The Bitter Lesson — Rich Sutton</a></li>
            <li><a class="card-link" href="https://arxiv.org/abs/2001.08361" target="_blank" rel="noreferrer">Scaling Laws for Neural Language Models</a></li>
          </ul>
        </article>
      </section>

      <section id="books" class="section">
        <div class="section-title">Book recommendations</div>
        <ul class="book-list">
          <li>Designing Data-Intensive Applications — Martin Kleppmann</li>
          <li>Designing Machine Learning Systems — Chip Huyen</li>
          <li>Deep Learning — Goodfellow, Bengio, Courville</li>
          <li>Surely You're Joking, Mr. Feynman! — Richard Feynman</li>
          <li>The Feynman Lectures on Physics — Richard Feynman</li>
          <li>Why We Sleep — Matthew Walker</li>
        </ul>
      </section>

      <section id="certifications" class="section">
        <div class="section-title">Certifications</div>
        <div class="card">
          <h3>Coursera</h3>
          <a href="https://www.coursera.org/learn/neural-networks-deep-learning?specialization=deep-learning" target="_blank">Neural Networks and Deep Learning</a><br>
          <a href="https://www.coursera.org/learn/deep-neural-network?specialization=deep-learning" target="_blank">Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization</a><br>
          <a href="https://www.coursera.org/learn/machine-learning-projects?specialization=deep-learning" target="_blank">Structured Machine Learning Projects</a><br>
          <a href="https://www.coursera.org/learn/convolutional-neural-networks?specialization=deep-learning" target="_blank">Convolutional Neural Networks</a><br>
          <a href="https://www.coursera.org/learn/nlp-sequence-models" target="_blank">Sequence Models</a><br>
          <a href="https://www.coursera.org/learn/introduction-tensorflow?specialization=deep-learning" target="_blank">Introduction to TensorFlow for AI, ML, and DL</a>
        </div>
        <div class="card">
          <h3>AWS Educate Pathways</h3>
          <a href="https://www.awseducate.com/student/s/pathways#ML" target="_blank">Machine Learning Scientist</a><br>
          <a href="https://www.awseducate.com/student/s/pathways#DS" target="_blank">Data Scientist</a><br>
          <a href="https://www.awseducate.com/student/s/pathways#CC" target="_blank">Cloud Computing 101</a>
        </div>
      </section>

      
    </main>
  </div>
</body>
</html>
